{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running route generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import osmnx as ox\n",
    "from osmnx._errors import InsufficientResponseError\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import math\n",
    "import statistics\n",
    "from collections import defaultdict, deque\n",
    "import random\n",
    "import heapq\n",
    "from shapely.geometry import Point\n",
    "\n",
    "ox.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure which tags should be added as graph edge or node attributes\n",
    "ox.settings.useful_tags_node = [\"highway\", \"junction\", \"railway\", \"ref\"]\n",
    "ox.settings.useful_tags_way = [\"access\", \"area\", \"bridge\", \"est_width\", \"highway\", \"junction\", \"landuse\", \"oneway\", \"ref\", \"service\", \"width\", \"lit\", \"surface\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retreive graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrives the graph around the start point in a route length / 2 radius\n",
    "def retrieve_graph(start_point, route_length):\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        # Retrieve all types of roads/pathways within the radius of route length / 2 from the start in the form of a graph\n",
    "        G = ox.graph.graph_from_point(center_point=start_point, dist=route_length/2, dist_type=\"network\", network_type=\"all\", simplify=True)\n",
    "\n",
    "        # When using a simplified graph the edges that are straight lines get no geometry attribute\n",
    "        # Making sure all edges include geometry attribute. Create GeoDataFrames for nodes and edges, with geometry attribute filled in for all edges\n",
    "        nodes, edges = ox.graph_to_gdfs(G, fill_edge_geometry=True)\n",
    "        # then re-create a graph from those GeoDataFrames\n",
    "        G = ox.graph_from_gdfs(nodes, edges, graph_attrs=G.graph)\n",
    "\n",
    "        # Make sure all edges actually have geometry data\n",
    "        for u, v, data in G.edges(keys=False, data=True):\n",
    "            assert \"geometry\" in data\n",
    "\n",
    "        return G\n",
    "    except ValueError:\n",
    "        # Return empty graph\n",
    "        return nx.MultiDiGraph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features / preferences\n",
    "This section retrieves graph data for features / preferences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds corresponding elevation data to all nodes in a graph. Using this, it calculates the edge grade and rise for all edges\n",
    "def add_elevation(graph):\n",
    "    # Assign elevation to all nodes using data from Open Topo Data, then calculate the edge grades\n",
    "    original_elevation_url = ox.settings.elevation_url_template\n",
    "    ox.settings.elevation_url_template = (\n",
    "        \"https://api.opentopodata.org/v1/aster30m?locations={locations}\"\n",
    "    )\n",
    "    graph = ox.elevation.add_node_elevations_google(graph, batch_size=100, pause=1)\n",
    "    graph = ox.elevation.add_edge_grades(graph)\n",
    "    ox.settings.elevation_url_template = original_elevation_url\n",
    "\n",
    "    for edge in graph.edges:\n",
    "        graph.edges[edge][\"rise\"] = graph.edges[edge][\"grade\"] * graph.edges[edge][\"length\"]\n",
    "\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_elevation_tags(graph):\n",
    "    # Get a list including all the absolute edge grades\n",
    "    grades = [\n",
    "        data[\"grade_abs\"]\n",
    "        for _, _, data in graph.edges(data=True)\n",
    "        if \"grade_abs\" in data\n",
    "    ]\n",
    "\n",
    "    # Calculate the 33rd and 66th percentiles\n",
    "    p33 = np.percentile(grades, 33)\n",
    "    p66 = np.percentile(grades, 66)\n",
    "\n",
    "    # Assign elevation tags\n",
    "    for edge in graph.edges:\n",
    "        edge_grade = graph.edges[edge][\"grade_abs\"]\n",
    "        if edge_grade <= p33:\n",
    "            graph.edges[edge][\"elev_tag\"] = \"Flat\"\n",
    "        elif edge_grade <= p66:\n",
    "            graph.edges[edge][\"elev_tag\"] = \"Moderate\"\n",
    "        else:\n",
    "            graph.edges[edge][\"elev_tag\"] = \"Hilly\"\n",
    "\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### POI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the X and Y values of a series of features. For lines and polygons the coordinates of the centroid is returned\n",
    "def get_feature_coordinates(features):\n",
    "    return features.geometry.centroid.x, features.geometry.centroid.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tags the closest edge to each viewpoint POI as a viewpoint edge\n",
    "def assign_viewpoint_edges(G, start_point, route_length):\n",
    "\n",
    "    tags = {\"tourism\": \"viewpoint\"}\n",
    "\n",
    "\n",
    "    # Find POI features\n",
    "    try:\n",
    "        viewpoint_features = ox.features.features_from_point(start_point, tags, route_length/2)\n",
    "    except InsufficientResponseError:\n",
    "        viewpoint_features = None\n",
    "    \n",
    "    if viewpoint_features is not None and not viewpoint_features.empty:\n",
    "        # Project graph to UTM, to be able to measure distance in meters\n",
    "        G_proj = ox.project_graph(G)\n",
    "\n",
    "        # Project the viewpoint features to the same CRS as the graph\n",
    "        viewpoint_features_proj = viewpoint_features.to_crs(G_proj.graph['crs'])\n",
    "\n",
    "        # Connect the viewpoint to their closest edge\n",
    "        viewpoint_features_proj_x, viewpoint_features_proj_y = get_feature_coordinates(viewpoint_features_proj)\n",
    "        viewpoint_edges = ox.distance.nearest_edges(G_proj, viewpoint_features_proj_x, viewpoint_features_proj_y)\n",
    "\n",
    "        for edge in viewpoint_edges:\n",
    "            G.edges[edge][\"Viewpoint\"] = True\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tags the closest edge to each tourism POI as a tourism edge\n",
    "def assign_tourism_edges(G, start_point, route_length):\n",
    "\n",
    "    tags = {\"toursim\": \"artwork\", \"memorial\": \"statue\", \"tourism\": \"attraction\"}\n",
    "\n",
    "\n",
    "    # Find POI features\n",
    "    try:\n",
    "        tourism_features = ox.features.features_from_point(start_point, tags, route_length/2)\n",
    "    except InsufficientResponseError:\n",
    "        tourism_features = None\n",
    "\n",
    "    if tourism_features is not None and not tourism_features.empty:\n",
    "        # Project graph to UTM, to be able to measure distance in meters\n",
    "        G_proj = ox.project_graph(G)\n",
    "        \n",
    "        # Project the tourism features to the same CRS as the graph\n",
    "        tourism_features_proj = tourism_features.to_crs(G_proj.graph['crs'])\n",
    "\n",
    "        # Connect the viewpoint to their closest edge\n",
    "        tourism_features_proj_x, tourism_features_proj_y = get_feature_coordinates(tourism_features_proj)\n",
    "        tourism_edges = ox.distance.nearest_edges(G_proj, tourism_features_proj_x, tourism_features_proj_y)\n",
    "\n",
    "        for edge in tourism_edges:\n",
    "            G.edges[edge][\"Tourism\"] = True\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tags all edges that are within 15 of park, wood or farmland as a nature edge\n",
    "def assign_nature_edges(G, start_point, route_length):\n",
    "\n",
    "    nature_feature_tags = {\"leisure\": \"park\", \"natural\": \"wood\", \"landuse\": \"farmland\"}\n",
    "\n",
    "    # Add nature data to edges\n",
    "    try:\n",
    "        nat_features = ox.features.features_from_point(start_point, nature_feature_tags, route_length/2)\n",
    "    except InsufficientResponseError:\n",
    "        nat_features = None\n",
    "\n",
    "    if nat_features is not None and not nat_features.empty:\n",
    "\n",
    "        # Project graph to UTM, to be able to measure distance in meters\n",
    "        G_proj = ox.project_graph(G)\n",
    "    \n",
    "        # Project the nature features to the same CRS as the graph\n",
    "        nat_features_proj = nat_features.to_crs(G_proj.graph['crs'])\n",
    "\n",
    "        # Create a buffer of 15m around the nature features\n",
    "        buffer_distance = 15\n",
    "        buffered_nature = nat_features_proj.buffer(buffer_distance)\n",
    "        buffered_union = gpd.GeoSeries(buffered_nature).union_all()\n",
    "\n",
    "        # Mark edges as near nature if they intersect the buffered union\n",
    "        for u, v, k, data in G_proj.edges(keys=True, data=True):\n",
    "            edge = (u, v, k)\n",
    "            geom = data.get(\"geometry\")\n",
    "            if geom is not None and geom.intersects(buffered_union):\n",
    "                G.edges[edge][\"Nature\"] = True\n",
    "            else:\n",
    "                G.edges[edge][\"Nature\"] = False\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lighting is already available via G.edges[edge][\"lit\"] = \"yes\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tag edges as either trail or road based on surface types of edge\n",
    "def assign_surface_types(G):\n",
    "    trail_surfaces ={\"fine_gravel\", \"gravel\", \"ground\", \"dirt\", \"grass\"}\n",
    "    trail_highways = {\"path\", \"track\"}\n",
    "\n",
    "    for u, v, k, data in G.edges(keys=True, data=True):\n",
    "        edge_type = data.get(\"highway\")\n",
    "        surface = data.get(\"surface\")\n",
    "\n",
    "        # Handle cases where edge_type and/or surface are lists\n",
    "        if isinstance(edge_type, list):\n",
    "            type_match = any(t in trail_highways for t in edge_type)\n",
    "        else:\n",
    "            type_match = edge_type in trail_highways\n",
    "\n",
    "        if isinstance(surface, list):\n",
    "            surface_match = any(s in trail_surfaces for s in surface)\n",
    "        else:\n",
    "            surface_match = surface in trail_surfaces\n",
    "\n",
    "        if type_match or surface_match:\n",
    "            G.edges[u, v, k][\"Trail\"] = True\n",
    "        else:\n",
    "            G.edges[u, v, k][\"Road\"] = True\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign edge weights\n",
    "This section assigns weights to edges based on preferences and attributes of the edges. The weighting is done differently for the approximation algorithms and the heuristic algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrives feature data for the specified features in features_wanted (same size as in preference vector)\n",
    "def retrieve_relevant_feature_data(G, pref, start_point, route_length, features_wanted):\n",
    "    \n",
    "    if features_wanted[0] == 1 or features_wanted[1] == 1:\n",
    "        G = add_elevation(G)\n",
    "        G = assign_elevation_tags(G)\n",
    "\n",
    "    if features_wanted[2] == 1 or features_wanted[3] == 1:\n",
    "        G = assign_surface_types(G)\n",
    "    if features_wanted[4] == 1:\n",
    "        G = assign_nature_edges(G, start_point, route_length)\n",
    "    if features_wanted[6] == 1:\n",
    "        G = assign_tourism_edges(G, start_point, route_length)\n",
    "    if features_wanted[7] == 1:\n",
    "        G = assign_viewpoint_edges(G, start_point, route_length)\n",
    "    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_attribute_values_approx_alg(edge_data):\n",
    "    attribute_values = 8 * [0]\n",
    "\n",
    "    # Flat and hilly attribute value\n",
    "    match edge_data.get(\"elev_tag\"):\n",
    "        case \"Flat\":\n",
    "            attribute_values[0] = 2\n",
    "            attribute_values[1] = 0.5\n",
    "        case \"Moderate\":\n",
    "            attribute_values[0] = 1\n",
    "            attribute_values[1] = 1\n",
    "        case \"Hilly\":\n",
    "            attribute_values[0] = 0.5\n",
    "            attribute_values[1] = 2\n",
    "    \n",
    "    # Road, trail, nature and lighting attribute values\n",
    "    if edge_data.get(\"Road\") == True:\n",
    "        attribute_values[2] = 2\n",
    "    else:\n",
    "        attribute_values[3] = 2\n",
    "\n",
    "    if edge_data.get(\"Nature\") == True:\n",
    "        attribute_values[4] = 2\n",
    "\n",
    "    if edge_data.get(\"lit\") == \"yes\":\n",
    "        attribute_values[5] = 2\n",
    "    \n",
    "    # POI attribute values\n",
    "    if edge_data.get(\"Tourism\") == True:\n",
    "        attribute_values[6] = 2\n",
    "    if edge_data.get(\"Viewpoint\") == True:\n",
    "        attribute_values[7] = 2\n",
    "\n",
    "    return attribute_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_weights_approx_alg(G, pref):\n",
    "    for u, v, k, data in G.edges(keys=True, data=True):\n",
    "        edge = (u, v, k)\n",
    "        attribute_values = calculate_attribute_values_approx_alg(data)\n",
    "        the_sum = sum(a * b for a, b in zip(pref, attribute_values))\n",
    "        G.edges[edge][\"weight_approx_alg\"] = data[\"length\"] * max(1, the_sum)\n",
    "        #G.edges[edge][\"weight_approx_alg\"] = data[\"length\"] * (the_sum+1)\n",
    "        \n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heuristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_attribute_values_heuristic(edge_data):\n",
    "    attribute_values = 8 * [1]\n",
    "\n",
    "    # Flat and hilly attribute value\n",
    "    match edge_data.get(\"elev_tag\"):\n",
    "        case \"Flat\":\n",
    "            attribute_values[0] = 0.7\n",
    "            attribute_values[1] = 1.3\n",
    "        case \"Moderate\":\n",
    "            attribute_values[0] = 1\n",
    "            attribute_values[1] = 1\n",
    "        case \"Hilly\":\n",
    "            attribute_values[1] = 1.3\n",
    "            attribute_values[1] = 0.7\n",
    "    \n",
    "    # Road, trail, nature and lighting attribute values\n",
    "    if edge_data.get(\"Road\") == True:\n",
    "        attribute_values[2] = 0.7\n",
    "    else:\n",
    "        attribute_values[3] = 0.7\n",
    "\n",
    "    if edge_data.get(\"Nature\") == True:\n",
    "        attribute_values[4] = 0.7\n",
    "\n",
    "    if edge_data.get(\"lit\") == \"yes\":\n",
    "        attribute_values[5] = 0.7\n",
    "\n",
    "    return attribute_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def assign_weights_heuristic(G, pref):\n",
    "    for u, v, k, data in G.edges(keys=True, data=True):\n",
    "        edge = (u, v, k)\n",
    "        attribute_values = calculate_attribute_values_heuristic(data)\n",
    "        G.edges[edge][\"weight_heuristic\"] = data[\"length\"] * math.prod(a ** b for a, b in zip(attribute_values, pref))\n",
    "        \n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Routing\n",
    "Here follows implementations of the three algorithms. In order for the greedy and DP-algorithm to work, we need edge lengths of whole numbers. So all edge lengths are rounded at the start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_edge_lengths(graph):\n",
    "    for u, v, key, data in graph.edges(keys=True, data=True):\n",
    "        original = data.get(\"length\", 1)\n",
    "        rounded = max(1, round(original))\n",
    "        data[\"length\"] = rounded\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greedy algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy(G, start, k):\n",
    "    # Calculate shortest path from every vertex to s using Dijkstra on reverse of graph\n",
    "    SPD = nx.single_source_dijkstra_path_length(G.reverse(copy=True), source=start, weight=\"length\")\n",
    "\n",
    "    walk = [start]\n",
    "    L = 0\n",
    "    u = start\n",
    "    Rep = defaultdict(int)  # repetition count of edges (u,v)\n",
    "\n",
    "    for _ in range(2*G.number_of_edges()):\n",
    "        candidates = []\n",
    "        L_current = L + SPD[u]\n",
    "\n",
    "        for n in G.neighbors(u):\n",
    "            # Make sure it does not go back to start for as long as possible\n",
    "            if start == n:\n",
    "                continue\n",
    "            \n",
    "            if n not in SPD:\n",
    "                continue\n",
    "            L_possible = L + G[u][n][0].get(\"length\") + SPD[n]\n",
    "            if abs(k - L_possible) <= abs(k - L_current):\n",
    "                candidates.append(n)\n",
    "\n",
    "        if not candidates:\n",
    "            break\n",
    "\n",
    "        min_rep_nodes = [c for c in candidates if Rep[(u, c)] == min(Rep[(u, c)] for c in candidates)]\n",
    "\n",
    "        c = max(min_rep_nodes, key=lambda c: G[u][c][0].get(\"weight_approx_alg\"))\n",
    "        Rep[(u, c)] += 1\n",
    "        Rep[(c, u)] += 1\n",
    "        walk.append(c)\n",
    "        L += G[u][c][0].get(\"length\")\n",
    "        u = c\n",
    "    \n",
    "    if u != start:\n",
    "        # append closest walk \n",
    "        shortest_path = nx.shortest_path(G, u, start, weight='length')\n",
    "        shortest_path.pop(0)\n",
    "        walk.extend(shortest_path)\n",
    "\n",
    "    return walk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamic_programming(graph, start, k, pref):\n",
    "    L_max = 2 * k\n",
    "    nodes = list(graph.nodes)\n",
    "    \n",
    "    # Initialize DP-matrix\n",
    "    DP = defaultdict(lambda: defaultdict(lambda: -math.inf))\n",
    "    DP[start][0] = 0\n",
    "\n",
    "    # Initialize recent edge history\n",
    "    recent = defaultdict(list)\n",
    "    prev = defaultdict(dict)\n",
    "    poi_count = defaultdict(int)\n",
    "\n",
    "    repeat_penalty = 2\n",
    "    max_history = 20\n",
    "\n",
    "    for ell in range(L_max + 1):\n",
    "        for u in nodes:\n",
    "            if DP[u][ell] == -math.inf:\n",
    "                continue\n",
    "            for v in graph.successors(u):\n",
    "                for key in graph[u][v]:  # To handle MultiDiGraph\n",
    "                    if u == start and ell > 0:\n",
    "                        continue\n",
    "\n",
    "                    edge_data = graph[u][v][key]\n",
    "                    edge_len = edge_data.get(\"length_scaled\")\n",
    "                    edge_weight = edge_data.get(\"weight_approx_alg\", 1)\n",
    "\n",
    "                    ell_prime = ell + edge_len\n",
    "                    if ell_prime > L_max:\n",
    "                        continue\n",
    "\n",
    "                    # Handle POI\n",
    "                    if pref[6] == 1 or pref[7] == 0:\n",
    "                        adjusting_factor = min(2, 1 + 0.1*poi_count[(u, ell)])\n",
    "                        edge_weight *= adjusting_factor\n",
    "                    \n",
    "                    # Handle repetiton\n",
    "                    #edge = (u, v)\n",
    "                    #if edge in recent[(u, ell)] or (v, u) in recent[(u, ell)]:\n",
    "                    #    edge_weight = min(-repeat_penalty*edge_weight, repeat_penalty*edge_weight)\n",
    "                    edge = (u, v)\n",
    "                    if edge in recent[(u, ell)] or (v, u) in recent[(u, ell)]:\n",
    "                        new_weight = DP[u][ell] - repeat_penalty*edge_weight\n",
    "                    else:\n",
    "                        new_weight = DP[u][ell] + edge_weight\n",
    "                    \n",
    "                    #new_weight = DP[u][ell] + edge_weight\n",
    "\n",
    "                    if new_weight > DP[v][ell_prime]:\n",
    "                        DP[v][ell_prime] = new_weight\n",
    "                        saved_recent = recent[(u, ell)][-(max_history - 1):]\n",
    "                        recent[(v, ell_prime)] = saved_recent + [edge]\n",
    "                        prev[v][ell_prime] = (u, ell)\n",
    "\n",
    "                        if edge_data.get(\"Toursim\") == True or edge_data.get(\"Viewpoint\") == True:\n",
    "                            poi_count[(v, ell_prime)] = poi_count[(u, ell)] + 1\n",
    "    \n",
    "    # Find best endpoint at s with minimal deviation from k\n",
    "    best_ell = None\n",
    "    min_deviation = math.inf\n",
    "    for ell in DP[start]:\n",
    "        if DP[start][ell] != -math.inf:\n",
    "            deviation = abs(ell - k)\n",
    "            if deviation < min_deviation:\n",
    "                best_ell = ell\n",
    "                min_deviation = deviation\n",
    "\n",
    "    # Backtrack to recover walk\n",
    "    walk_nodes = deque()\n",
    "    current = (start, best_ell)\n",
    "    walk_nodes.appendleft(current[0])  # Start node\n",
    "\n",
    "    while current[1] in prev.get(current[0], {}):\n",
    "        u, ell = prev[current[0]][current[1]]\n",
    "        walk_nodes.appendleft(u)\n",
    "        current = (u, ell)\n",
    "\n",
    "    return list(walk_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamic prograaming approximation scheme\n",
    "def dp_approximation_scheme(G, start, k, pref, epsilon):\n",
    "    delta = epsilon * k / G.number_of_edges()\n",
    "\n",
    "    for edge in G.edges:\n",
    "        G.edges[edge][\"length_scaled\"] = math.ceil(G.edges[edge][\"length\"] / delta) \n",
    "\n",
    "    k_prime = math.ceil(k / delta)\n",
    "    print(k_prime)\n",
    "    return dynamic_programming(G, start, k_prime, pref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heuristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combines 3 routes into 1 for the heuristic\n",
    "def combine_routes(route1, route2, route3):\n",
    "    route1.pop()\n",
    "    route2.pop()\n",
    "    return route1 + route2 + route3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns isochrone nodes of radius +- 10% around the center node\n",
    "def get_isochrone_nodes(graph, center_node, radius):\n",
    "    outer_subgraph = nx.ego_graph(graph, center_node, radius=radius*1.1, distance=\"length\")\n",
    "    inner_subgraph = nx.ego_graph(graph, center_node, radius=radius*0.9, distance=\"length\")\n",
    "\n",
    "    return outer_subgraph.nodes - inner_subgraph.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find set of random pairs of via-vertices\n",
    "def find_random_pairs_of_via_vertices(G, start_vertex, route_length):\n",
    "    isochrone = get_isochrone_nodes(G, start_vertex, route_length/3)\n",
    "\n",
    "    valid_pairs_of_via_vertices = list()\n",
    "    \n",
    "    random.seed(42)\n",
    "    random_via_vertices = random.sample(list(isochrone), min(10, len(list(isochrone))))\n",
    "  \n",
    "    for vv1 in random_via_vertices:\n",
    "        isochrone2 = get_isochrone_nodes(G, vv1, route_length/3)\n",
    "        for vv2 in isochrone2:\n",
    "            if vv2 in isochrone and vv2 != start_vertex:\n",
    "                valid_pairs_of_via_vertices.append((vv1, vv2))\n",
    "                break\n",
    "\n",
    "    return valid_pairs_of_via_vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Shortest path between vertices that takes POIs into account\n",
    "def shortest_path_poi(G, vertex1, vertex2, poi_tags):\n",
    "    heap = [(0, vertex1, [], 0)]  # (distance, node, path, poi_count)\n",
    "    best = {}  # best distance to each node\n",
    "\n",
    "    shortest_to_target = float(\"inf\")\n",
    "    best_path = None\n",
    "\n",
    "    while heap:\n",
    "        dist_u, u, path, poi_count = heapq.heappop(heap)\n",
    "        path = path + [u]\n",
    "\n",
    "        # Check if we already have found a better path to this node\n",
    "        if u in best and best[u] <= dist_u:\n",
    "            continue\n",
    "        best[u] = dist_u\n",
    "\n",
    "        # Update target info if we reach it\n",
    "        if u == vertex2:\n",
    "            if dist_u < shortest_to_target:\n",
    "                shortest_to_target = dist_u\n",
    "                best_path = path\n",
    "            continue  # Don't return yet â€” there could be a better path\n",
    "\n",
    "        for v in G.neighbors(u):\n",
    "            for key, data in G[u][v].items():\n",
    "                weight = data.get(\"weight_heuristic\", 0)\n",
    "                # Adjust weight based on poi_count\n",
    "                adjusting_factor = max(0.1, 0.5-0.1*poi_count)\n",
    "                weight *= adjusting_factor\n",
    "                \n",
    "                is_poi = False\n",
    "                if \"Tourism\" in poi_tags:\n",
    "                    is_poi = data.get(\"tourism\", False)\n",
    "                if \"Viewpoint\" in poi_tags and not is_poi:\n",
    "                    is_poi = data.get(\"viewpoint\", False)\n",
    "\n",
    "                new_poi_count = poi_count + 1 if is_poi else poi_count\n",
    "                heapq.heappush(heap, (dist_u + weight, v, path, new_poi_count))\n",
    "\n",
    "    return best_path  # Will be None if no path was found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates a route for the heuristic algorithm based on start node and a pair of via-vertices\n",
    "def generate_route(G, start, viavertex1, viavertex2, pref):\n",
    "    \n",
    "    poi_tags = []\n",
    "    \n",
    "    if pref[6] == 1:\n",
    "        poi_tags.append(\"Tourism\")\n",
    "    if pref[7] == 1:\n",
    "        poi_tags.append(\"Viewpoint\")\n",
    "        \n",
    "    if poi_tags:\n",
    "        route1 = shortest_path_poi(G, start, viavertex1, poi_tags)\n",
    "        route2 = shortest_path_poi(G, viavertex1, viavertex2, poi_tags)\n",
    "        route3 = shortest_path_poi(G, viavertex2, start, poi_tags)\n",
    "    else:\n",
    "        try:\n",
    "            route1 = nx.shortest_path(G, source=start, target=viavertex1, weight=\"weight_heuristic\")\n",
    "            route2 = nx.shortest_path(G, source=viavertex1, target=viavertex2, weight=\"weight_heuristic\")\n",
    "            route3 = nx.shortest_path(G, source=viavertex2, target=start, weight=\"weight_heuristic\")\n",
    "        except NetworkXNoPath:\n",
    "            return [start]\n",
    "    \n",
    "    return combine_routes(route1, route2, route3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the weight of a route from the heuristic algorithm\n",
    "def weight_of_route(route_gdf):\n",
    "    total_weight = 0\n",
    "    for edge, edge_info in route_gdf.iterrows():\n",
    "        total_weight += edge_info.get(\"weight_heuristic\")\n",
    "    return total_weight\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heuristic(G, start_vertex, route_length, pref):\n",
    "\n",
    "    possible_via_vertices = find_random_pairs_of_via_vertices(G, start_vertex, route_length)\n",
    "    best_route = [start_vertex]\n",
    "    best_route_weight = math.inf\n",
    "    \n",
    "    for i, pair_of_via_vertices in enumerate(possible_via_vertices):\n",
    "        route = generate_route(G, start_vertex, pair_of_via_vertices[0], pair_of_via_vertices[1], pref)\n",
    "        weight = weight_of_route(ox.routing.route_to_gdf(G, route, weight=\"weight_heuristic\"))\n",
    "        if weight < best_route_weight:\n",
    "            best_route = route\n",
    "            best_route_weight = weight\n",
    "    \n",
    "    return best_route"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics about route\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that returns all necessary statistics for a route\n",
    "def get_stats_of_route(route_length, route_gdf):\n",
    "\n",
    "    total_length = 0\n",
    "    \n",
    "    length_of_repetition = 0\n",
    "    visited_edges = set()\n",
    "\n",
    "    total_elevation = 0\n",
    "\n",
    "    length_of_road = 0\n",
    "    length_of_trail = 0\n",
    "    length_of_nature = 0\n",
    "    length_of_lighting = 0\n",
    "    \n",
    "    number_of_viewpoints = 0\n",
    "    number_of_tourism = 0\n",
    "\n",
    "    for edge, edge_info in route_gdf.iterrows():\n",
    "        # Update total length\n",
    "        edge_length = edge_info.get(\"length\")\n",
    "        total_length += edge_length\n",
    "\n",
    "        # Update repetition\n",
    "        u, v, _ = edge\n",
    "        if (u,v) in visited_edges or (v,u) in visited_edges:\n",
    "            length_of_repetition += edge_length\n",
    "        else:\n",
    "            visited_edges.add((u,v))\n",
    "\n",
    "        # Update elevation\n",
    "        if edge_info.get(\"rise\") and edge_info.get(\"rise\") > 0:\n",
    "            total_elevation += edge_info.get(\"rise\")\n",
    "\n",
    "        # Update surface\n",
    "        if edge_info.get(\"Road\") == True:\n",
    "            length_of_road += edge_length\n",
    "        elif edge_info.get(\"Trail\") == True:\n",
    "            length_of_trail += edge_length\n",
    "            \n",
    "        # Update nature\n",
    "        if edge_info.get(\"Nature\") == True:\n",
    "            length_of_nature += edge_length\n",
    "\n",
    "        # Update lighting\n",
    "        if edge_info.get(\"lit\") == \"yes\":\n",
    "            length_of_lighting += edge_length\n",
    "\n",
    "\n",
    "        # Update POI\n",
    "        if (edge_info.get(\"Viewpoint\") == True) and not ((u,v) in visited_edges or (v,u) in visited_edges):\n",
    "            number_of_viewpoints += 1\n",
    "\n",
    "        if (edge_info.get(\"Tourism\") == True) and not ((u,v) in visited_edges or (v,u) in visited_edges):\n",
    "            number_of_tourism += 1\n",
    "\n",
    "    statistics = dict()\n",
    "    \n",
    "    statistics[\"length\"] = total_length\n",
    "\n",
    "    statistics[\"length_deviation\"] = abs(total_length - route_length)\n",
    "    \n",
    "    if total_length > 0:\n",
    "        statistics[\"repetition\"] = length_of_repetition / total_length\n",
    "        statistics[\"road\"] = length_of_road / total_length\n",
    "        statistics[\"trail\"] = length_of_trail / total_length\n",
    "        statistics[\"nature\"] = length_of_nature / total_length\n",
    "        statistics[\"lighting\"] = length_of_lighting / total_length\n",
    "    else:\n",
    "        statistics[\"repetition\"] = 0\n",
    "        statistics[\"road\"] = 0\n",
    "        statistics[\"trail\"] = 0\n",
    "        statistics[\"nature\"] = 0\n",
    "        statistics[\"lighting\"] = 0       \n",
    "        \n",
    "    statistics[\"elevation\"] = total_elevation\n",
    "\n",
    "    statistics[\"viewpoint\"] = number_of_viewpoints\n",
    "    statistics[\"tourism\"] = number_of_tourism\n",
    "\n",
    "    return statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Coordinates of the starting points for the datasets\n",
    "\n",
    "dataset_1_lat = 57.702582\n",
    "dataset_1_long = 11.964342\n",
    "\n",
    "dataset_2_lat = 59.435529 \n",
    "dataset_2_long = 17.952240\n",
    "\n",
    "dataset_3_lat = 61.119136\n",
    "dataset_3_long = 14.620491\n",
    "\n",
    "dataset_4_lat = 55.383511\n",
    "dataset_4_long = 14.063187"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepares the graph for a route starting in a location with a specific route length\n",
    "def prepare_graph(lat, long, route_length, pref, features_wanted):\n",
    "    start_point = lat, long\n",
    "\n",
    "    # Retrieve graph and relevant feature data\n",
    "    G = retrieve_graph(start_point, route_length)\n",
    "    \n",
    "    if G.number_of_nodes() != 0:\n",
    "        G = retrieve_relevant_feature_data(G, pref, start_point, route_length, features_wanted)\n",
    "\n",
    "        # Assign edge weights based on preferences and feature data\n",
    "        G = assign_weights_approx_alg(G, pref)\n",
    "        G = assign_weights_heuristic(G, pref)\n",
    "\n",
    "        # Round the length of edges \n",
    "        G = round_edge_lengths(G)\n",
    "    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "k=1000\n",
    "epsilon = 500\n",
    "G1 = 34300\n",
    "G2 = 11902\n",
    "G3 = 2303\n",
    "G4 = 345\n",
    "epsilon1 = 100\n",
    "epsilon2 = G2/(k/2)\n",
    "epsilon3 = G3/(k/2)\n",
    "epsilon4 = G4/(k/2)\n",
    "\n",
    "#delta = (epsilon * k) / G1\n",
    "\n",
    "#k_prime = math.ceil(k / delta)\n",
    "#print(math.ceil(20 / delta))\n",
    "\n",
    "print(\"Dataset 1 k: \" + str(math.ceil(k / ((epsilon * k) / G1))))\n",
    "print(\"Dataset 2 k: \" + str(math.ceil(k / ((epsilon * k) / G2))))\n",
    "print(\"Dataset 3 k: \" + str(math.ceil(k / ((epsilon * k) / G3))))\n",
    "print(\"Dataset 4 k: \" + str(math.ceil(k / ((epsilon * k) / G4))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate deviation and repetition diagram\n",
    "def dev_and_rep_diagram(lat, long, fig_dev, fig_rep, axs_dev, axs_rep, dataset_num):\n",
    "    \n",
    "    longest_k = 1000\n",
    "    pref = [0,0,0,0,0,0,0,0]\n",
    "    \n",
    "    G = prepare_graph(lat, long, longest_k, pref, pref)\n",
    "    \n",
    "    start_vertex = ox.nearest_nodes(G, long, lat)\n",
    "    \n",
    "    k_values = []\n",
    "\n",
    "    # Store value of deviation for the three algorithms\n",
    "    greedy_values = []\n",
    "    dp_values = []\n",
    "    heuristic_values = []\n",
    "    \n",
    "    # Store repetition of the three algorithms\n",
    "    greedy_rep = []\n",
    "    dp_rep = []\n",
    "    heuristic_rep = []\n",
    "    \n",
    "    for k in range(100, longest_k+1, 100):\n",
    "        print(k)\n",
    "        \n",
    "        if k > 0:\n",
    "            greedy_route = greedy(G, start_vertex, k)\n",
    "            #dp_route = dp_approximation_scheme(G, start_vertex, k, pref, 100)\n",
    "            # Test av epsilon\n",
    "            dp_route = dp_approximation_scheme(G, start_vertex, k, pref, G.number_of_edges() / 500)\n",
    "            heuristic_route = heuristic(G, start_vertex, k, pref)\n",
    "        else:\n",
    "            greedy_route = [start_vertex]\n",
    "            dp_route = [start_vertex]\n",
    "            heuristic_route = [start_vertex]\n",
    "        \n",
    "        if len(greedy_route) == 1 or len(dp_route) == 1 or len(heuristic_route) == 1:\n",
    "            G.add_edge(start_vertex, start_vertex, key=0, length=0, geometry=None, weight_approx_alg=0, weight_heuristic=0)\n",
    "            \n",
    "        greedy_stats = get_stats_of_route(k, ox.routing.route_to_gdf(G, greedy_route, weight=\"weight_approx_alg\"))\n",
    "        dp_stats = get_stats_of_route(k, ox.routing.route_to_gdf(G, dp_route, weight=\"weight_approx_alg\"))\n",
    "        heuristic_stats = get_stats_of_route(k, ox.routing.route_to_gdf(G, heuristic_route, weight=\"weight_heuristic\"))\n",
    "        \n",
    "        \n",
    "        k_values.append(k)\n",
    "        greedy_values.append(greedy_stats[\"length_deviation\"])\n",
    "        dp_values.append(dp_stats[\"length_deviation\"])\n",
    "        heuristic_values.append(heuristic_stats[\"length_deviation\"])\n",
    "        \n",
    "        greedy_rep.append(greedy_stats[\"repetition\"]*100)\n",
    "        dp_rep.append(dp_stats[\"repetition\"]*100)\n",
    "        heuristic_rep.append(heuristic_stats[\"repetition\"]*100)\n",
    "    \n",
    "    # Plot deviation\n",
    "    plt.figure(fig_dev.number)\n",
    "    plt.sca(axs_dev) # Select subplot\n",
    "    plt.plot(k_values, greedy_values, label='Greedy algorithm', marker='o')\n",
    "    plt.plot(k_values, dp_values, label='Dynamic programming algorithm', marker='s')\n",
    "    plt.plot(k_values, heuristic_values, label='Heuristic algorithm', marker='^')\n",
    "    plt.xlabel('k (m)')\n",
    "    plt.ylabel('Deviation from k (m)')\n",
    "    axs_dev.set_title(\"Dataset \" + str(dataset_num))\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot repetition\n",
    "    plt.figure(fig_rep.number)\n",
    "    plt.sca(axs_rep) # Select subplot\n",
    "    plt.plot(k_values, greedy_rep, label='Greedy algorithm', marker='o')\n",
    "    plt.plot(k_values, dp_rep, label='Dynamic programming algorithm', marker='s')\n",
    "    plt.plot(k_values, heuristic_rep, label='Heuristic algorithm', marker='^')\n",
    "    plt.xlabel('k (m)')\n",
    "    plt.ylabel('Repetition (\\% of k)')\n",
    "    axs_rep.set_title(\"Dataset \" + str(dataset_num))\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "# Create figures\n",
    "\n",
    "figdev, axsdev = plt.subplots(2, 2, figsize=(12, 9))\n",
    "figrep, axsrep = plt.subplots(2, 2, figsize=(12, 9))\n",
    "\n",
    "dev_and_rep_diagram(dataset_1_lat, dataset_1_long, figdev, figrep, axsdev[0,0], axsrep[0,0], 1)\n",
    "dev_and_rep_diagram(dataset_2_lat, dataset_2_long, figdev, figrep, axsdev[0,1], axsrep[0,1], 2)\n",
    "dev_and_rep_diagram(dataset_3_lat, dataset_3_long, figdev, figrep, axsdev[1,0], axsrep[1,0], 3)\n",
    "dev_and_rep_diagram(dataset_4_lat, dataset_4_long, figdev, figrep, axsdev[1,1], axsrep[1,1], 4)\n",
    "\n",
    "# Save figs\n",
    "figdev.savefig(\"deviation_diagram.png\", bbox_inches='tight')\n",
    "figrep.savefig(\"repetition_diagram.png\", bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generates table with statistics regarding elevation\n",
    "def elevation_stats(lat, long, epsilon):\n",
    "    pref_flat = [1,0,0,0,0,0,0,0]\n",
    "    pref_hilly = [0,1,0,0,0,0,0,0]\n",
    "    no_pref = [0,0,0,0,0,0,0,0]\n",
    "    \n",
    "    route_length = 5000\n",
    "    \n",
    "    G_flat = prepare_graph(lat, long, route_length, pref_flat, pref_flat)\n",
    "    G_hilly = prepare_graph(lat, long, route_length, pref_hilly, pref_hilly)\n",
    "    G_no_pref = prepare_graph(lat, long, route_length, no_pref, pref_flat)\n",
    "    \n",
    "    # Flat preference \n",
    "    start_vertex_flat = ox.nearest_nodes(G_flat, long, lat)\n",
    "        \n",
    "    greedy_route_flat = greedy(G_flat, start_vertex_flat, route_length)\n",
    "    dp_route_flat = dp_approximation_scheme(G_flat, start_vertex_flat, route_length, pref_flat, epsilon)\n",
    "    heuristic_route_flat = heuristic(G_flat, start_vertex_flat, route_length, pref_flat)\n",
    "        \n",
    "    if len(greedy_route_flat) == 1 or len(dp_route_flat) == 1 or len(heuristic_route_flat) == 1:\n",
    "        G_flat.add_edge(start_vertex_flat, start_vertex_flat, key=0, length=0, geometry=None, weight_approx_alg=0, weight_heuristic=0)        \n",
    "        \n",
    "    # Get all stats\n",
    "    greedy_stats_flat = get_stats_of_route(route_length, ox.routing.route_to_gdf(G_flat, greedy_route_flat, weight=\"weight_approx_alg\"))\n",
    "    dp_stats_flat = get_stats_of_route(route_length, ox.routing.route_to_gdf(G_flat, dp_route_flat, weight=\"weight_approx_alg\"))\n",
    "    heuristic_stats_flat = get_stats_of_route(route_length, ox.routing.route_to_gdf(G_flat, heuristic_route_flat, weight=\"weight_heuristic\"))\n",
    "    \n",
    "    # Hilly preference\n",
    "    start_vertex_hilly = ox.nearest_nodes(G_hilly, long, lat)\n",
    "        \n",
    "    greedy_route_hilly = greedy(G_hilly, start_vertex_hilly, route_length)\n",
    "    dp_route_hilly = dp_approximation_scheme(G_hilly, start_vertex_hilly, route_length, pref_hilly, epsilon)\n",
    "    heuristic_route_hilly = heuristic(G_hilly, start_vertex_hilly, route_length, pref_hilly)\n",
    "        \n",
    "    if len(greedy_route_hilly) == 1 or len(dp_route_hilly) == 1 or len(heuristic_route_hilly) == 1:\n",
    "        G_hilly.add_edge(start_vertex_hilly, start_vertex_hilly, key=0, length=0, geometry=None, weight_approx_alg=0, weight_heuristic=0)        \n",
    "        \n",
    "    # Get all stats\n",
    "    greedy_stats_hilly = get_stats_of_route(route_length, ox.routing.route_to_gdf(G_hilly, greedy_route_hilly, weight=\"weight_approx_alg\"))\n",
    "    dp_stats_hilly = get_stats_of_route(route_length, ox.routing.route_to_gdf(G_hilly, dp_route_hilly, weight=\"weight_approx_alg\"))\n",
    "    heuristic_stats_hilly = get_stats_of_route(route_length, ox.routing.route_to_gdf(G_hilly, heuristic_route_hilly, weight=\"weight_heuristic\"))\n",
    "    \n",
    "    # No preference\n",
    "    start_vertex_no_pref = ox.nearest_nodes(G_no_pref, long, lat)\n",
    "        \n",
    "    greedy_route_no_pref = greedy(G_no_pref, start_vertex_no_pref, route_length)\n",
    "    dp_route_no_pref = dp_approximation_scheme(G_no_pref, start_vertex_no_pref, route_length, no_pref, epsilon)\n",
    "    heuristic_route_no_pref = heuristic(G_no_pref, start_vertex_no_pref, route_length, no_pref)\n",
    "        \n",
    "    if len(greedy_route_no_pref) == 1 or len(dp_route_no_pref) == 1 or len(heuristic_route_no_pref) == 1:\n",
    "        G_no_pref.add_edge(start_vertex_no_pref, start_vertex_no_pref, key=0, length=0, geometry=None, weight_approx_alg=0, weight_heuristic=0)        \n",
    "        \n",
    "    # Get all stats\n",
    "    greedy_stats_no_pref = get_stats_of_route(route_length, ox.routing.route_to_gdf(G_no_pref, greedy_route_no_pref, weight=\"weight_approx_alg\"))\n",
    "    dp_stats_no_pref = get_stats_of_route(route_length, ox.routing.route_to_gdf(G_no_pref, dp_route_no_pref, weight=\"weight_approx_alg\"))\n",
    "    heuristic_stats_no_pref = get_stats_of_route(route_length, ox.routing.route_to_gdf(G_no_pref, heuristic_route_no_pref, weight=\"weight_heuristic\"))\n",
    "        \n",
    "    # Create the dataframe\n",
    "    df = pd.DataFrame(columns=[\"Algorithm\", \"Deviation\", \"Repetition\", \"Elevation\"])\n",
    "\n",
    "    # Add rows to df\n",
    "    df.loc[len(df)] = [\"Greedy flat\", 100*greedy_stats_flat[\"length_deviation\"]/route_length, 100*greedy_stats_flat[\"repetition\"], 1000*greedy_stats_flat[\"elevation\"]/ greedy_stats_flat[\"length\"]]\n",
    "    df.loc[len(df)] = [\"DP flat\", 100*dp_stats_flat[\"length_deviation\"]/route_length, 100*dp_stats_flat[\"repetition\"], 1000*dp_stats_flat[\"elevation\"]/ dp_stats_flat[\"length\"]]\n",
    "    df.loc[len(df)] = [\"Heuristic flat\", 100*heuristic_stats_flat[\"length_deviation\"]/route_length, 100*heuristic_stats_flat[\"repetition\"], 1000*heuristic_stats_flat[\"elevation\"]/ heuristic_stats_flat[\"length\"]]   \n",
    "    df.loc[len(df)] = [\"Greedy hilly\", 100*greedy_stats_hilly[\"length_deviation\"]/route_length, 100*greedy_stats_hilly[\"repetition\"], 1000*greedy_stats_hilly[\"elevation\"]/ greedy_stats_hilly[\"length\"]]\n",
    "    df.loc[len(df)] = [\"DP hilly\", 100*dp_stats_hilly[\"length_deviation\"]/route_length, 100*dp_stats_hilly[\"repetition\"], 1000*dp_stats_hilly[\"elevation\"]/ dp_stats_hilly[\"length\"]]\n",
    "    df.loc[len(df)] = [\"Heuristic hilly\", 100*heuristic_stats_hilly[\"length_deviation\"]/route_length, 100*heuristic_stats_hilly[\"repetition\"], 1000*heuristic_stats_hilly[\"elevation\"]/ heuristic_stats_hilly[\"length\"]]\n",
    "    df.loc[len(df)] = [\"Greedy no pref\", 100*greedy_stats_no_pref[\"length_deviation\"]/route_length, 100*greedy_stats_no_pref[\"repetition\"], 1000*greedy_stats_no_pref[\"elevation\"]/ greedy_stats_no_pref[\"length\"]]\n",
    "    df.loc[len(df)] = [\"DP no pref\", 100*dp_stats_no_pref[\"length_deviation\"]/route_length, 100*dp_stats_no_pref[\"repetition\"], 1000*dp_stats_no_pref[\"elevation\"]/ dp_stats_no_pref[\"length\"]]\n",
    "    df.loc[len(df)] = [\"Heuristic no pref\", 100*heuristic_stats_no_pref[\"length_deviation\"]/route_length, 100*heuristic_stats_no_pref[\"repetition\"], 1000*heuristic_stats_no_pref[\"elevation\"]/ heuristic_stats_no_pref[\"length\"]]            \n",
    "        \n",
    "    return df\n",
    "        \n",
    "print(\"Dataset 1 \\n\" + str(elevation_stats(dataset_1_lat, dataset_1_long, 100)))\n",
    "print(\"Dataset 2 \\n\" + str(elevation_stats(dataset_2_lat, dataset_2_long, 100)))\n",
    "print(\"Dataset 3 \\n\" + str(elevation_stats(dataset_3_lat, dataset_3_long, 100)))\n",
    "print(\"Dataset 4 \\n\" + str(elevation_stats(dataset_4_lat, dataset_4_long, 100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generates table with statistics regarding surface\n",
    "def surface_stats(lat, long, epsilon):\n",
    "    pref_road = [0,0,1,0,0,0,0,0]\n",
    "    pref_trail = [0,0,0,1,0,0,0,0]\n",
    "    no_pref = [0,0,0,0,0,0,0,0]\n",
    "    \n",
    "    route_length = 5000\n",
    "    \n",
    "    G_road = prepare_graph(lat, long, route_length, pref_road, pref_road)\n",
    "    G_trail = prepare_graph(lat, long, route_length, pref_trail, pref_trail)\n",
    "    G_no_pref = prepare_graph(lat, long, route_length, no_pref, pref_road)\n",
    "    \n",
    "    # Road preference \n",
    "    start_vertex_road = ox.nearest_nodes(G_road, long, lat)\n",
    "        \n",
    "    greedy_route_road = greedy(G_road, start_vertex_road, route_length)\n",
    "    dp_route_road = dp_approximation_scheme(G_road, start_vertex_road, route_length, pref_road, epsilon)\n",
    "    heuristic_route_road = heuristic(G_road, start_vertex_road, route_length, pref_road)\n",
    "        \n",
    "    if len(greedy_route_road) == 1 or len(dp_route_road) == 1 or len(heuristic_route_road) == 1:\n",
    "        G_road.add_edge(start_vertex_road, start_vertex_road, key=0, length=0, geometry=None, weight_approx_alg=0, weight_heuristic=0)        \n",
    "        \n",
    "    # Get all stats\n",
    "    greedy_stats_road = get_stats_of_route(route_length, ox.routing.route_to_gdf(G_road, greedy_route_road, weight=\"weight_approx_alg\"))\n",
    "    dp_stats_road = get_stats_of_route(route_length, ox.routing.route_to_gdf(G_road, dp_route_road, weight=\"weight_approx_alg\"))\n",
    "    heuristic_stats_road = get_stats_of_route(route_length, ox.routing.route_to_gdf(G_road, heuristic_route_road, weight=\"weight_heuristic\"))\n",
    "    \n",
    "    # Trail preference\n",
    "    start_vertex_trail = ox.nearest_nodes(G_trail, long, lat)\n",
    "        \n",
    "    greedy_route_trail = greedy(G_trail, start_vertex_trail, route_length)\n",
    "    dp_route_trail = dp_approximation_scheme(G_trail, start_vertex_trail, route_length, pref_trail, epsilon)\n",
    "    heuristic_route_trail = heuristic(G_trail, start_vertex_trail, route_length, pref_trail)\n",
    "        \n",
    "    if len(greedy_route_trail) == 1 or len(dp_route_trail) == 1 or len(heuristic_route_trail) == 1:\n",
    "        G_trail.add_edge(start_vertex_trail, start_vertex_trail, key=0, length=0, geometry=None, weight_approx_alg=0, weight_heuristic=0)        \n",
    "        \n",
    "    # Get all stats\n",
    "    greedy_stats_trail = get_stats_of_route(route_length, ox.routing.route_to_gdf(G_trail, greedy_route_trail, weight=\"weight_approx_alg\"))\n",
    "    dp_stats_trail = get_stats_of_route(route_length, ox.routing.route_to_gdf(G_trail, dp_route_trail, weight=\"weight_approx_alg\"))\n",
    "    heuristic_stats_trail = get_stats_of_route(route_length, ox.routing.route_to_gdf(G_trail, heuristic_route_trail, weight=\"weight_heuristic\"))\n",
    "    \n",
    "    # No preference\n",
    "    start_vertex_no_pref = ox.nearest_nodes(G_no_pref, long, lat)\n",
    "        \n",
    "    greedy_route_no_pref = greedy(G_no_pref, start_vertex_no_pref, route_length)\n",
    "    dp_route_no_pref = dp_approximation_scheme(G_no_pref, start_vertex_no_pref, route_length, no_pref, epsilon)\n",
    "    heuristic_route_no_pref = heuristic(G_no_pref, start_vertex_no_pref, route_length, no_pref)\n",
    "        \n",
    "    if len(greedy_route_no_pref) == 1 or len(dp_route_no_pref) == 1 or len(heuristic_route_no_pref) == 1:\n",
    "        G_no_pref.add_edge(start_vertex_no_pref, start_vertex_no_pref, key=0, length=0, geometry=None, weight_approx_alg=0, weight_heuristic=0)        \n",
    "        \n",
    "    # Get all stats\n",
    "    greedy_stats_no_pref = get_stats_of_route(route_length, ox.routing.route_to_gdf(G_no_pref, greedy_route_no_pref, weight=\"weight_approx_alg\"))\n",
    "    dp_stats_no_pref = get_stats_of_route(route_length, ox.routing.route_to_gdf(G_no_pref, dp_route_no_pref, weight=\"weight_approx_alg\"))\n",
    "    heuristic_stats_no_pref = get_stats_of_route(route_length, ox.routing.route_to_gdf(G_no_pref, heuristic_route_no_pref, weight=\"weight_heuristic\"))\n",
    "        \n",
    "    # Create the dataframe\n",
    "    df = pd.DataFrame(columns=[\"Algorithm\", \"Deviation\", \"Repetition\", \"Road\", \"Trail\"])\n",
    "\n",
    "    # Add rows to df\n",
    "    df.loc[len(df)] = [\"Greedy road\", 100*greedy_stats_road[\"length_deviation\"]/route_length, 100*greedy_stats_road[\"repetition\"], 100*greedy_stats_road[\"road\"], 100*greedy_stats_road[\"trail\"]]\n",
    "    df.loc[len(df)] = [\"Greedy trail\", 100*greedy_stats_trail[\"length_deviation\"]/route_length, 100*greedy_stats_trail[\"repetition\"], 100*greedy_stats_trail[\"road\"], 100*greedy_stats_trail[\"trail\"]]\n",
    "    df.loc[len(df)] = [\"Greedy no pref\", 100*greedy_stats_no_pref[\"length_deviation\"]/route_length, 100*greedy_stats_no_pref[\"repetition\"], 100*greedy_stats_no_pref[\"road\"], 100*greedy_stats_no_pref[\"trail\"]]\n",
    "\n",
    "    df.loc[len(df)] = [\"DP road\", 100*dp_stats_road[\"length_deviation\"]/route_length, 100*dp_stats_road[\"repetition\"], 100*dp_stats_road[\"road\"], 100*dp_stats_road[\"trail\"]]\n",
    "    df.loc[len(df)] = [\"DP trail\", 100*dp_stats_trail[\"length_deviation\"]/route_length, 100*dp_stats_trail[\"repetition\"], 100*dp_stats_trail[\"road\"], 100*dp_stats_trail[\"trail\"]]\n",
    "    df.loc[len(df)] = [\"DP no pref\", 100*dp_stats_no_pref[\"length_deviation\"]/route_length, 100*dp_stats_no_pref[\"repetition\"], 100*dp_stats_no_pref[\"road\"], 100*dp_stats_no_pref[\"trail\"]]\n",
    "    \n",
    "    df.loc[len(df)] = [\"Heuristic road\", 100*heuristic_stats_road[\"length_deviation\"]/route_length, 100*heuristic_stats_road[\"repetition\"], 100*heuristic_stats_road[\"road\"], 100*heuristic_stats_road[\"trail\"]]\n",
    "    df.loc[len(df)] = [\"Heuristic trail\", 100*heuristic_stats_trail[\"length_deviation\"]/route_length, 100*heuristic_stats_trail[\"repetition\"], 100*heuristic_stats_trail[\"road\"], 100*heuristic_stats_trail[\"trail\"]]\n",
    "    df.loc[len(df)] = [\"Heuristic no pref\", 100*heuristic_stats_no_pref[\"length_deviation\"]/route_length, 100*heuristic_stats_no_pref[\"repetition\"], 100*heuristic_stats_no_pref[\"road\"], 100*heuristic_stats_no_pref[\"trail\"]]       \n",
    "        \n",
    "    return df\n",
    "        \n",
    "print(\"Dataset 1 \\n\" + str(surface_stats(dataset_1_lat, dataset_1_long, 100)))\n",
    "print(\"Dataset 2 \\n\" + str(surface_stats(dataset_2_lat, dataset_2_long, 100)))\n",
    "print(\"Dataset 3 \\n\" + str(surface_stats(dataset_3_lat, dataset_3_long, 100)))\n",
    "print(\"Dataset 4 \\n\" + str(surface_stats(dataset_4_lat, dataset_4_long, 100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generates table with statistics regarding POI\n",
    "def poi_stats(lat, long, epsilon):\n",
    "    pref_tourism = [0,0,0,0,0,0,1,0]\n",
    "    pref_viewpoint = [0,0,0,0,0,0,0,1]\n",
    "    pref_poi = [0,0,0,0,0,0,1,1]\n",
    "    no_pref = [0,0,0,0,0,0,0,0]\n",
    "    \n",
    "    route_length = 5000\n",
    "    \n",
    "    G_tourism = prepare_graph(lat, long, route_length, pref_tourism, pref_poi)\n",
    "    G_viewpoint = prepare_graph(lat, long, route_length, pref_viewpoint, pref_poi)\n",
    "    G_no_pref = prepare_graph(lat, long, route_length, no_pref, pref_poi)\n",
    "    \n",
    "    # Tourism preference \n",
    "    start_vertex_tourism = ox.nearest_nodes(G_tourism, long, lat)\n",
    "        \n",
    "    greedy_route_tourism = greedy(G_tourism, start_vertex_tourism, route_length)\n",
    "    dp_route_tourism = dp_approximation_scheme(G_tourism, start_vertex_tourism, route_length, pref_tourism, epsilon)\n",
    "    heuristic_route_tourism = heuristic(G_tourism, start_vertex_tourism, route_length, pref_tourism)\n",
    "        \n",
    "    if len(greedy_route_tourism) == 1 or len(dp_route_tourism) == 1 or len(heuristic_route_tourism) == 1:\n",
    "        G_tourism.add_edge(start_vertex_tourism, start_vertex_tourism, key=0, length=0, geometry=None, weight_approx_alg=0, weight_heuristic=0)        \n",
    "        \n",
    "    # Get all stats\n",
    "    greedy_stats_tourism = get_stats_of_route(route_length, ox.routing.route_to_gdf(G_tourism, greedy_route_tourism, weight=\"weight_approx_alg\"))\n",
    "    dp_stats_tourism = get_stats_of_route(route_length, ox.routing.route_to_gdf(G_tourism, dp_route_tourism, weight=\"weight_approx_alg\"))\n",
    "    heuristic_stats_tourism = get_stats_of_route(route_length, ox.routing.route_to_gdf(G_tourism, heuristic_route_tourism, weight=\"weight_heuristic\"))\n",
    "    \n",
    "    # Viewpoint preference\n",
    "    start_vertex_viewpoint = ox.nearest_nodes(G_viewpoint, long, lat)\n",
    "        \n",
    "    greedy_route_viewpoint = greedy(G_viewpoint, start_vertex_viewpoint, route_length)\n",
    "    dp_route_viewpoint = dp_approximation_scheme(G_viewpoint, start_vertex_viewpoint, route_length, pref_viewpoint, epsilon)\n",
    "    heuristic_route_viewpoint = heuristic(G_viewpoint, start_vertex_viewpoint, route_length, pref_viewpoint)\n",
    "        \n",
    "    if len(greedy_route_viewpoint) == 1 or len(dp_route_viewpoint) == 1 or len(heuristic_route_viewpoint) == 1:\n",
    "        G_viewpoint.add_edge(start_vertex_viewpoint, start_vertex_viewpoint, key=0, length=0, geometry=None, weight_approx_alg=0, weight_heuristic=0)        \n",
    "        \n",
    "    # Get all stats\n",
    "    greedy_stats_viewpoint = get_stats_of_route(route_length, ox.routing.route_to_gdf(G_viewpoint, greedy_route_viewpoint, weight=\"weight_approx_alg\"))\n",
    "    dp_stats_viewpoint = get_stats_of_route(route_length, ox.routing.route_to_gdf(G_viewpoint, dp_route_viewpoint, weight=\"weight_approx_alg\"))\n",
    "    heuristic_stats_viewpoint = get_stats_of_route(route_length, ox.routing.route_to_gdf(G_viewpoint, heuristic_route_viewpoint, weight=\"weight_heuristic\"))\n",
    "    \n",
    "    # No preference\n",
    "    start_vertex_no_pref = ox.nearest_nodes(G_no_pref, long, lat)\n",
    "        \n",
    "    greedy_route_no_pref = greedy(G_no_pref, start_vertex_no_pref, route_length)\n",
    "    dp_route_no_pref = dp_approximation_scheme(G_no_pref, start_vertex_no_pref, route_length, no_pref, epsilon)\n",
    "    heuristic_route_no_pref = heuristic(G_no_pref, start_vertex_no_pref, route_length, no_pref)\n",
    "        \n",
    "    if len(greedy_route_no_pref) == 1 or len(dp_route_no_pref) == 1 or len(heuristic_route_no_pref) == 1:\n",
    "        G_no_pref.add_edge(start_vertex_no_pref, start_vertex_no_pref, key=0, length=0, geometry=None, weight_approx_alg=0, weight_heuristic=0)        \n",
    "        \n",
    "    # Get all stats\n",
    "    greedy_stats_no_pref = get_stats_of_route(route_length, ox.routing.route_to_gdf(G_no_pref, greedy_route_no_pref, weight=\"weight_approx_alg\"))\n",
    "    dp_stats_no_pref = get_stats_of_route(route_length, ox.routing.route_to_gdf(G_no_pref, dp_route_no_pref, weight=\"weight_approx_alg\"))\n",
    "    heuristic_stats_no_pref = get_stats_of_route(route_length, ox.routing.route_to_gdf(G_no_pref, heuristic_route_no_pref, weight=\"weight_heuristic\"))\n",
    "        \n",
    "    # Create the dataframe\n",
    "    df = pd.DataFrame(columns=[\"Algorithm\", \"Deviation\", \"Repetition\", \"Tourism\", \"Viewpoint\"])\n",
    "\n",
    "    # Add rows to df\n",
    "    df.loc[len(df)] = [\"Greedy tourism\", 100*greedy_stats_tourism[\"length_deviation\"]/route_length, 100*greedy_stats_tourism[\"repetition\"], greedy_stats_tourism[\"tourism\"], greedy_stats_tourism[\"viewpoint\"]]\n",
    "    df.loc[len(df)] = [\"Greedy viewpoint\", 100*greedy_stats_viewpoint[\"length_deviation\"]/route_length, 100*greedy_stats_viewpoint[\"repetition\"], greedy_stats_viewpoint[\"tourism\"], greedy_stats_viewpoint[\"viewpoint\"]]\n",
    "    df.loc[len(df)] = [\"Greedy no pref\", 100*greedy_stats_no_pref[\"length_deviation\"]/route_length, 100*greedy_stats_no_pref[\"repetition\"], greedy_stats_no_pref[\"tourism\"], greedy_stats_no_pref[\"viewpoint\"]]\n",
    "\n",
    "    df.loc[len(df)] = [\"DP tourism\", 100*dp_stats_tourism[\"length_deviation\"]/route_length, 100*dp_stats_tourism[\"repetition\"], dp_stats_tourism[\"tourism\"], dp_stats_tourism[\"viewpoint\"]]\n",
    "    df.loc[len(df)] = [\"DP viewpoint\", 100*dp_stats_viewpoint[\"length_deviation\"]/route_length, 100*dp_stats_viewpoint[\"repetition\"], dp_stats_viewpoint[\"tourism\"], dp_stats_viewpoint[\"viewpoint\"]]\n",
    "    df.loc[len(df)] = [\"DP no pref\", 100*dp_stats_no_pref[\"length_deviation\"]/route_length, 100*dp_stats_no_pref[\"repetition\"], dp_stats_no_pref[\"tourism\"], dp_stats_no_pref[\"viewpoint\"]]\n",
    "    \n",
    "    df.loc[len(df)] = [\"Heuristic tourism\", 100*heuristic_stats_tourism[\"length_deviation\"]/route_length, 100*heuristic_stats_tourism[\"repetition\"], heuristic_stats_tourism[\"tourism\"], heuristic_stats_tourism[\"viewpoint\"]]\n",
    "    df.loc[len(df)] = [\"Heuristic viewpoint\", 100*heuristic_stats_viewpoint[\"length_deviation\"]/route_length, 100*heuristic_stats_viewpoint[\"repetition\"], heuristic_stats_viewpoint[\"tourism\"], heuristic_stats_viewpoint[\"viewpoint\"]]\n",
    "    df.loc[len(df)] = [\"Heuristic no pref\", 100*heuristic_stats_no_pref[\"length_deviation\"]/route_length, 100*heuristic_stats_no_pref[\"repetition\"], heuristic_stats_no_pref[\"tourism\"], heuristic_stats_no_pref[\"viewpoint\"]]       \n",
    "        \n",
    "    return df\n",
    "        \n",
    "print(\"Dataset 1 \\n\" + str(poi_stats(dataset_1_lat, dataset_1_long, 100)))\n",
    "print(\"Dataset 2 \\n\" + str(poi_stats(dataset_2_lat, dataset_2_long, 100)))\n",
    "print(\"Dataset 3 \\n\" + str(poi_stats(dataset_3_lat, dataset_3_long, 100)))\n",
    "print(\"Dataset 4 \\n\" + str(poi_stats(dataset_4_lat, dataset_4_long, 100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generates table with statistics regarding features like nature or lighting\n",
    "def feature_stats(lat, long, epsilon, pref, feature_tag):\n",
    "    no_pref = [0,0,0,0,0,0,0,0]\n",
    "    \n",
    "    route_length = 5000\n",
    "    \n",
    "    G_pref = prepare_graph(lat, long, route_length, pref, pref)\n",
    "    G_no_pref = prepare_graph(lat, long, route_length, no_pref, pref)\n",
    "    \n",
    "    # Preference \n",
    "    start_vertex_pref = ox.nearest_nodes(G_pref, long, lat)\n",
    "        \n",
    "    greedy_route_pref = greedy(G_pref, start_vertex_pref, route_length)\n",
    "    dp_route_pref = dp_approximation_scheme(G_pref, start_vertex_pref, route_length, pref, epsilon)\n",
    "    heuristic_route_pref = heuristic(G_pref, start_vertex_pref, route_length, pref)\n",
    "        \n",
    "    if len(greedy_route_pref) == 1 or len(dp_route_pref) == 1 or len(heuristic_route_pref) == 1:\n",
    "        G_pref.add_edge(start_vertex_pref, start_vertex_pref, key=0, length=0, geometry=None, weight_approx_alg=0, weight_heuristic=0)        \n",
    "        \n",
    "    # Get all stats\n",
    "    greedy_stats_pref = get_stats_of_route(route_length, ox.routing.route_to_gdf(G_pref, greedy_route_pref, weight=\"weight_approx_alg\"))\n",
    "    dp_stats_pref = get_stats_of_route(route_length, ox.routing.route_to_gdf(G_pref, dp_route_pref, weight=\"weight_approx_alg\"))\n",
    "    heuristic_stats_pref = get_stats_of_route(route_length, ox.routing.route_to_gdf(G_pref, heuristic_route_pref, weight=\"weight_heuristic\"))\n",
    "    \n",
    "    # No preference\n",
    "    start_vertex_no_pref = ox.nearest_nodes(G_no_pref, long, lat)\n",
    "        \n",
    "    greedy_route_no_pref = greedy(G_no_pref, start_vertex_no_pref, route_length)\n",
    "    dp_route_no_pref = dp_approximation_scheme(G_no_pref, start_vertex_no_pref, route_length, no_pref, epsilon)\n",
    "    heuristic_route_no_pref = heuristic(G_no_pref, start_vertex_no_pref, route_length, no_pref)\n",
    "        \n",
    "    if len(greedy_route_no_pref) == 1 or len(dp_route_no_pref) == 1 or len(heuristic_route_no_pref) == 1:\n",
    "        G_no_pref.add_edge(start_vertex_no_pref, start_vertex_no_pref, key=0, length=0, geometry=None, weight_approx_alg=0, weight_heuristic=0)        \n",
    "        \n",
    "    # Get all stats\n",
    "    greedy_stats_no_pref = get_stats_of_route(route_length, ox.routing.route_to_gdf(G_no_pref, greedy_route_no_pref, weight=\"weight_approx_alg\"))\n",
    "    dp_stats_no_pref = get_stats_of_route(route_length, ox.routing.route_to_gdf(G_no_pref, dp_route_no_pref, weight=\"weight_approx_alg\"))\n",
    "    heuristic_stats_no_pref = get_stats_of_route(route_length, ox.routing.route_to_gdf(G_no_pref, heuristic_route_no_pref, weight=\"weight_heuristic\"))\n",
    "        \n",
    "    # Create the dataframe\n",
    "    df = pd.DataFrame(columns=[\"Algorithm\", \"Deviation\", \"Repetition\", \"Feature\"])\n",
    "\n",
    "    # Add rows to df\n",
    "    df.loc[len(df)] = [\"Greedy pref\", 100*greedy_stats_pref[\"length_deviation\"]/route_length, 100*greedy_stats_pref[\"repetition\"], 100*greedy_stats_pref[feature_tag]/ greedy_stats_pref[\"length\"]]\n",
    "    df.loc[len(df)] = [\"DP pref\", 100*dp_stats_pref[\"length_deviation\"]/route_length, 100*dp_stats_pref[\"repetition\"], 100*dp_stats_pref[feature_tag]/ dp_stats_pref[\"length\"]]\n",
    "    df.loc[len(df)] = [\"Heuristic pref\", 100*heuristic_stats_pref[\"length_deviation\"]/route_length, 100*heuristic_stats_pref[\"repetition\"], 100*heuristic_stats_pref[feature_tag]/ heuristic_stats_pref[\"length\"]]   \n",
    "    df.loc[len(df)] = [\"Greedy no pref\", 100*greedy_stats_no_pref[\"length_deviation\"]/route_length, 100*greedy_stats_no_pref[\"repetition\"], 100*greedy_stats_no_pref[feature_tag]/ greedy_stats_no_pref[\"length\"]]\n",
    "    df.loc[len(df)] = [\"DP no pref\", 100*dp_stats_no_pref[\"length_deviation\"]/route_length, dp_stats_no_pref[\"repetition\"], 100*dp_stats_no_pref[feature_tag]/ dp_stats_no_pref[\"length\"]]\n",
    "    df.loc[len(df)] = [\"Heuristic no pref\", 100*heuristic_stats_no_pref[\"length_deviation\"]/route_length, 100*heuristic_stats_no_pref[\"repetition\"], 100*heuristic_stats_no_pref[feature_tag]/ heuristic_stats_no_pref[\"length\"]]            \n",
    "        \n",
    "    return df\n",
    "\n",
    "nature_pref = [0,0,0,0,1,0,0,0]\n",
    "nature_tag = \"nature\"\n",
    "\n",
    "print(\"Nature \\n\")\n",
    "print(\"Dataset 1 \\n\" + str(feature_stats(dataset_1_lat, dataset_1_long, 100, nature_pref, nature_tag)))\n",
    "print(\"Dataset 2 \\n\" + str(feature_stats(dataset_2_lat, dataset_2_long, 100, nature_pref, nature_tag)))\n",
    "print(\"Dataset 3 \\n\" + str(feature_stats(dataset_3_lat, dataset_3_long, 100, nature_pref, nature_tag)))\n",
    "print(\"Dataset 4 \\n\" + str(feature_stats(dataset_4_lat, dataset_4_long, 100, nature_pref, nature_tag)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the routes for all algorithms \n",
    "def visualize_algorithms(lat, long, route_length, pref, dataset_num):\n",
    "    G = prepare_graph(lat, long, route_length, pref, pref)\n",
    "    \n",
    "    start_vertex = ox.nearest_nodes(G, long, lat)\n",
    "        \n",
    "    greedy_route = greedy(G, start_vertex, route_length)\n",
    "    dp_route = dp_approximation_scheme(G, start_vertex, route_length, pref, 100)\n",
    "    heuristic_route = heuristic(G, start_vertex, route_length, pref)\n",
    "    \n",
    "    \n",
    "    fig = plt.figure(figsize=(15, 5))\n",
    "    gs = gridspec.GridSpec(1, 3, wspace=0)  # Minimal horizontal space\n",
    "    axs = [fig.add_subplot(gs[0, i]) for i in range(3)]\n",
    "    plt.subplots_adjust(wspace=0.0)\n",
    "    \n",
    "    # Create bounding box that fits all routes \n",
    "    G_greedy = G.subgraph(greedy_route)\n",
    "    \n",
    "    nodes_df_greedy = ox.graph_to_gdfs(G_greedy, edges=False)\n",
    "    north_greedy, south_greedy = nodes_df_greedy['y'].max(), nodes_df_greedy['y'].min()\n",
    "    east_greedy, west_greedy = nodes_df_greedy['x'].max(), nodes_df_greedy['x'].min()\n",
    "    \n",
    "    G_dp = G.subgraph(dp_route)\n",
    "    \n",
    "    nodes_df_dp = ox.graph_to_gdfs(G_dp, edges=False)\n",
    "    north_dp, south_dp = nodes_df_dp['y'].max(), nodes_df_dp['y'].min()\n",
    "    east_dp, west_dp = nodes_df_dp['x'].max(), nodes_df_dp['x'].min()\n",
    "    \n",
    "    G_heuristic = G.subgraph(heuristic_route)\n",
    "    \n",
    "    nodes_df_heuristic = ox.graph_to_gdfs(G_heuristic, edges=False)\n",
    "    north_heuristic, south_heuristic = nodes_df_heuristic['y'].max(), nodes_df_heuristic['y'].min()\n",
    "    east_heuristic, west_heuristic = nodes_df_heuristic['x'].max(), nodes_df_heuristic['x'].min()\n",
    "    \n",
    "\n",
    "    pad = 0.001\n",
    "    north = max(north_greedy, north_dp, north_heuristic)\n",
    "    south = min(south_greedy, south_dp, south_heuristic)\n",
    "    east = max(east_greedy, east_dp, east_heuristic)\n",
    "    west = min(west_greedy, west_dp, west_heuristic)\n",
    "    bbox = (west-pad, south-pad, east+pad, north+pad)\n",
    "\n",
    "    axs[0].set_title(\"Greedy algorithm\")    \n",
    "    ox.plot_graph(G=G, ax=axs[0], bbox=bbox, node_size=0, edge_linewidth=0.5, edge_color='gray', show=False, close=False)\n",
    "    ox.plot_graph_route(G=G,\n",
    "                        bbox=bbox,\n",
    "                        show=False,\n",
    "                        close=False,\n",
    "                        route=greedy_route,\n",
    "                        route_color=\"blue\",\n",
    "                        route_linewidths=4,\n",
    "                        ax=axs[0])\n",
    "\n",
    "    axs[1].set_title(\"Dynamic programming algorithm\")\n",
    "    ox.plot_graph(G, ax=axs[1], bbox=bbox, node_size=0, edge_linewidth=0.5, edge_color='gray', show=False, close=False)\n",
    "    ox.plot_graph_route(G=G,\n",
    "                        bbox=bbox,\n",
    "                        show=False,\n",
    "                        close=False,                       \n",
    "                        route=dp_route,\n",
    "                        route_color=\"green\",\n",
    "                        route_linewidths=4,\n",
    "                        ax=axs[1])\n",
    "    \n",
    "    axs[2].set_title(\"Heuristic algorithm\")\n",
    "    ox.plot_graph(G, ax=axs[2], bbox=bbox, node_size=0, edge_linewidth=0.5, edge_color='gray', show=False, close=False)\n",
    "    ox.plot_graph_route(G=G,\n",
    "                        bbox=bbox,\n",
    "                        show=False,\n",
    "                        close=False,                       \n",
    "                        route=heuristic_route,\n",
    "                        route_color=\"red\",\n",
    "                        route_linewidths=4,\n",
    "                        ax=axs[2])\n",
    "    \n",
    "    axs[0].margins(0)\n",
    "    axs[1].margins(0)\n",
    "    axs[2].margins(0)\n",
    "    \n",
    "    filename = \"plotalgs_\" + str(dataset_num) + \".png\"\n",
    "    plt.savefig(filename, dpi=400, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "# Plot the routes of algorithms for all datasets    \n",
    "pref = [0,0,0,0,0,0,0,0]\n",
    "    \n",
    "visualize_algorithms(dataset_1_lat, dataset_1_long, 1500, pref, 1)\n",
    "visualize_algorithms(dataset_2_lat, dataset_2_long, 1500, pref, 2)\n",
    "visualize_algorithms(dataset_3_lat, dataset_3_long, 1500, pref, 3)\n",
    "visualize_algorithms(dataset_4_lat, dataset_4_long, 1500, pref, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra\n",
    "Here are some extra code for a few things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualization of isochrones\n",
    "def visualize_isochrone(lat, long, route_length):\n",
    "\n",
    "    no_pref = [0,0,0,0,0,0,0,0]\n",
    "\n",
    "    G = prepare_graph(lat, long, route_length, no_pref, no_pref)\n",
    "\n",
    "    start_vertex = ox.nearest_nodes(G, long, lat)\n",
    "\n",
    "    node_colors = {}\n",
    "    node_sizes = {}\n",
    "    \n",
    "    node_colors[start_vertex] = \"yellow\"\n",
    "    node_sizes[start_vertex] = 35\n",
    "\n",
    "    # The isochrone includes all possible via-vertices\n",
    "    isochrone = get_isochrone_nodes(G, start_vertex, route_length/3)\n",
    "\n",
    "    for node in isochrone:\n",
    "        node_colors[node] = \"red\"\n",
    "        node_sizes[node] = 15\n",
    "    \n",
    "    # Choose a via-vertex in isochrone randomly\n",
    "    via_vertex1 = random.sample(list(isochrone), 1)[0]\n",
    "    node_colors[via_vertex1] = \"orange\"\n",
    "    node_sizes[via_vertex1] = 35\n",
    "    \n",
    "    isochrone2 = get_isochrone_nodes(G, via_vertex1, route_length/3)\n",
    "\n",
    "    possible_via_vertex2 = []\n",
    "\n",
    "    for node in isochrone2:\n",
    "        if node == start_vertex or node == via_vertex1:\n",
    "            continue\n",
    "        elif node in isochrone:\n",
    "            possible_via_vertex2.append(node)\n",
    "            node_colors[node] = \"blue\"\n",
    "            node_sizes[node] = 15\n",
    "        else:\n",
    "            node_colors[node] = \"green\"\n",
    "            node_sizes[node] = 15\n",
    "\n",
    "    nc = [node_colors[node] if node in node_colors else \"none\" for node in G.nodes()]\n",
    "    ns = [node_sizes[node] if node in node_sizes else 0 for node in G.nodes()]\n",
    "\n",
    "    fig, ax = ox.plot.plot_graph(G, node_color=nc, node_size=ns, edge_linewidth=0.5, edge_color='gray', bgcolor=\"white\", show=False, close=False)\n",
    "    \n",
    "    plt.savefig(\"visualize_isochrone.png\", dpi=400, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "visualize_isochrone(dataset_4_lat, dataset_4_long, 3000)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/base-cpu:m129"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
